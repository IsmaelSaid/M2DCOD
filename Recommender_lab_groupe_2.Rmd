---
title: "Guide d'utilisation recommenderlab"
author: "Etienne Ismael"
date: "`r Sys.Date()`"
output:
  beamer_presentation: default
  slidy_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library("recommenderlab")
require(methods)
```

# Partie 1.

## Chargement des fichiers

Nous travaillons avec les données anime. Ces données représentent les notes attribuées aux animés par 5000 utilisateurs. Les données sont au format dat. La méthode read.csv() lit un fichier au format table et créer un dataframe à partir de ces données

```{r echo = TRUE}
# read_csv retourne un data.frame
anime_history <-read.csv("datasets/anime/anime_history.dat",
                         header = TRUE,
                         sep = "\t")
anime_info <-read.csv("datasets/anime/anime_info.dat",
                      header = TRUE,
                      sep = "\t")
anime_ratings <-read.csv("datasets/anime/anime_ratings.dat",
                         header = TRUE,
                         sep = "\t")

class(anime_ratings) # données au format dataframe
```

## Rappels sur les data.frame

C'est une structure pour stocker des jeux de données. Pour accèder aux elements d'un dataframe, nous utilisons les brackets [lignes,colonnes]

```{r echo=TRUE,  results='hide'}
anime_ratings[1:5,1:3] #lignes 1 à 5, colonnes 1 à 3
anime_ratings[1:5, c("User_ID","Anime_ID","Feedback")]
# Cette ligne ralentit considéralement l'exportation en pdf. 
# anime_ratings[-c(1, 2)]  #uniquement la colonne 3
summary(anime_ratings) #statistique de base
```

```{r echo=FALSE}
knitr::kable(anime_ratings[1:5,1:3])
```

## Coercition

La coercition consiste à convertir un objet en une classe donnée. Par défaut, read.csv retourne un data.frame. Il est nécessaire de le transformer vers un format adapté pour pouvoir y faire des opérations supplémentaires.

## Coercition du data.frame vers un objet realratingsMatrix

Il est plus facile de sélectionner les utilisateurs et les items que l'on souhaite manipuler et les comparer avec les realrattingsmatrix. Un objet realratingsmatrix stocke les données dans un format sparse Matrix qui enregistre uniquement les valeurs non vides. Les valeurs vides sont représentées par le caractère "."

```{r, echo=TRUE,results='hide'}
rrm_anime <- as(anime_ratings,'realRatingMatrix')
# opération inverse 
head(as(rrm_anime,'data.frame'))
head(getRatingMatrix(rrm_anime)) #affiche la matrice au format sparse Matrix
```

```{r echo=FALSE}
knitr::kable(head(as(rrm_anime,'data.frame')))
```

## Fonctions intéressantes realRatingsMatrix

-   nratings
-   dim
-   colCounts
-   rowCounts
-   colMeans
-   rowMeans

## Propriétés des données

```{r,echo=TRUE,results='hide'}
dim(rrm_anime) #  4714 Lignes 7157 colonnes  
nratings(rrm_anime) # 419943 notes
```

## Donneés interessantes

```{r echo=TRUE}
head(colMeans(rrm_anime)) # signification
head(colCounts(rrm_anime)) # signification 
head(rowCounts(rrm_anime)) # signification
```

## Visualisation realRatingsMatrix

```{r, echo=TRUE}
image(rrm_anime[1:10,1:30])
```

## Histogramme

```{r, fig.width = 10,echo=TRUE}
hist(getRatings(rrm_anime),breaks = 10,labels = TRUE)
```

## Normalisation

<!-- La normalisation tente de réduire le biais de notation individuel en centrant les données par ligne. On a le choix d'utiliser une normalisation par centrage (défaut) ou par zscore. Par centre: On soustrait chaque note disponible de la moyenne des notes de cet utilisateur (ligne) On peut normaliser les notes avec la fonction normalize. La fonction prend en argument un objet RealRatingMatrix -->

```{r, echo=TRUE}
#normalisation par centre
nrrmx_anime_ratings =  normalize(rrm_anime)
head(getRatings(nrrmx_anime_ratings))
#normalisation par z-score
nzrrmx_anime_ratings <- normalize(rrm_anime, method="Z-score")
head(getRatings(nzrrmx_anime_ratings))
```

## Histogramme des notes normalisées

```{r,echo=TRUE}
hist(getRatings(normalize(rrm_anime)),breaks=100)
```

## Binarisation des données

La binarisation permet de réduire la note à un avis positif (1) ou un avis négatif (0). La facon la plus simple de binariser est d'utiliser la fonction binarize().On peut fixer un seuil de notation.

```{r}
brmx_anime_ratings <- as(anime_ratings,'binaryRatingMatrix')
#les notes qui sont à >=  minRating sont positif
anime_binary <- binarize(rrm_anime, minRating=4)
class(anime_binary)
# getRatings(anime_binary)
```

## Visualisation binary ratings matrix

On peut aussi visualiser les binary ratings matrix avec la méthode image.

```{r}
  #image(brmx_anime_ratings[1:10,1:30])
  image(anime_binary[1:10,1:30])
  as(anime_binary[1:10,1:30], "matrix")
```

# Evaluation des modèles de recommendations

## Mise en situation

## Identifier le problème

Qu'est ce que je pourrais bien lui recommander ?

```{r,echo=TRUE}
image(rrm_anime[1:1,1:25])
```

## Comprendre les données

```{r,echo=FALSE}
totals_ratings = 419943
```

-   $X \in \mathbb{R}^{4714}$ Ensemble des utilisateurs.
-   $S \in \mathbb{R}^{7157}$ Ensemble des Animés.
-   Constat : notes biaisées.
-   Nombre total de notes : 419943.
-   200 utilisateurs ont notées une fois.
-   1033 Anime ont été notées une fois.

## Nettoyer et réduire le volume de donnée

```{r,echo=FALSE,results='hide'}
dataset = rrm_anime[rowCounts(rrm_anime) > 50 ,colCounts(rrm_anime) > 50]
dataset = dataset[1:1000,1:1000]
reduction = (419943-402195) * 100 / 419943
reduction
dataset
```

-   $X \in \mathbb{R}^{3691}$Ensemble des utilisateurs.
-   $S \in \mathbb{R}^{3531}$ Ensemble des Animés.
-   Nombre total de notes : 402195
-   Reduction de $4.22\%$

## Préparer ses données

```{r,echo=FALSE,results='hide'}
set.seed(123)
e <- evaluationScheme(
  train = 0.9,
  dataset[1:200],
  method="split",
  given=9,
  goodRating=5)
```

### Séparer ses données

``` r
evaluationScheme(data, method, train, k...)
```

### Normaliser ses données

``` r
normalise(data, method, train, k...)
```

## Vérifiez la répartition des notes

```{r,echo=FALSE}
custom_summary = data.frame(
  training_data = colMeans(getData(e,"train")),
  validation_data = colMeans(getData(e,"known"))
)
boxplot(custom_summary)
```

## Les différents modèles

-   POPULAR
-   IBCF
-   UBCF

## Instancier un modèle de recommendation

```{r,echo=TRUE}
r1 <- Recommender(getData(e,"train"), method = "IBCF")
r2 <- Recommender(getData(e,"train"), method = "POPULAR")
r3 <- Recommender(getData(e,"train"), method = "UBCF")
```

## Réaliser une prediction

```{r,echo=TRUE}
p1 <- predict(r1, getData(e,"known"),type="ratings")
p2 <- predict(r2, getData(e, "known"),type="ratings")
p3 <- predict(r3, getData(e, "known"),type = "ratings")
```

## Evaluer la prediction sur les notes

-   Métriques

    -   $MSE = \frac{1}{|R|} \displaystyle\sum_{(x,i)\in R}{(\hat{r_{xi}} - r_{xi})}$
    -   $RMSE = \sqrt{\frac{1}{|R|} \displaystyle\sum_{(x,i)\in R}{(\hat{r_{xi}} - r_{xi})}}$
    -   $MAE = \frac{1}{|R|} \displaystyle\sum_{(x,i)\in R}{|\hat{r_{xi}} - r_{xi}|}$

-   Résultats

```{r,echo=FALSE}
error <- rbind(
  IBCF = calcPredictionAccuracy(p1, getData(e, "unknown")),
  POPULAR = calcPredictionAccuracy(p2, getData(e, "unknown")),
  UBCF = calcPredictionAccuracy(p3, getData(e, "unknown"))
  )
knitr::kable(data.frame(error))
```

## Evaluation d'un algorithme de recommendation

Evaluation par validation croisée 4 folds

```{r,echo=TRUE,results='hide'}
eval_cross_topn_scheme <- evaluationScheme(
  train = 0.9,
  dataset,
  method="cross",
  k=4,
  given=1,
  goodRating=5)
```

```{r,echo=FALSE,results='hide'}
results_ibcf <- evaluate(eval_cross_topn_scheme,
                    method='IBCF',
                    type = "ratings")
result_ibcf = getResults(results_ibcf)
rmse_ibcf = lapply(result_ibcf,function(x) x[[1,"RMSE"]])
cv_metrics = data.frame(rmse_ibcf = unlist(rmse_ibcf))
```

## RMSE IBCF

```{r}
boxplot(cv_metrics)
```

## Evaluation d'un algorithme de recommendation top-N

```{r,results='hide',echo=TRUE}
scheme <- evaluationScheme(dataset,
                           method="cross",k=2,
                           given=1,
                           goodRating=5)

results <- evaluate(scheme,
                    method="POPULAR",
                    type = "topNList",
                    n=c(seq(10, 500, by = 50)))

random <- evaluate(scheme,
                    method="RANDOM",
                    type = "topNList",
                    n=c(seq(10, 500, by = 50)))
```

## Métriques

-   TP : est un résultat où le modèle prédit *correctement* la classe *positive*.

-   TN : est un résultat où le modèle prédit *correctement* la classe *negative*.

-   FP : est un résultat où le modèle prédit *incorrectement* la classe *positive*.

-   FN : est un résultat où le modèle prédit *de manière incorrecte* la classe *négative*.

## Métriques

-   Precision : Quelle proportion d'identifications positives était effectivement correcte ?
    -   $Precision=\frac{TP}{TP+FP}$
-   Rappel : Quelle proportion de résultats positifs réels a été identifiée correctement ?
    -   $Rappel=\frac{TP}{TP+FN}$

## Calculer les différentes métriques

```{r,echo=FALSE}
knitr::kable(data.frame(avg(results)))
```

## Courbe ROC Popular

```{r,echo=TRUE}
plot(results,"ROC",annotate=TRUE)
```

## Courbe ROC Random

```{r,echo=TRUE}
plot(random,"ROC",annotate=TRUE)
```

## Prec/Rec

```{r,echo=TRUE}
plot(results,"prec/rec",annotate=TRUE)
```

## Comparaison de plusieurs algorithmes 

```{r}

```

```{r}
scheme <- evaluationScheme(dataset,
                           method="split",
                           train = .9,
                           given=-5,
                           goodRating=5)
```

```{r,echo=TRUE}
algorithms <- list(
  "random items" = list(name="RANDOM", param=NULL),
  "popular items" = list(name="POPULAR", param=NULL),
  "user-based CF" = list(name="UBCF", param=list(nn=50)),
  "item-based CF" = list(name="IBCF", param=list(k=50)),
  "SVD approximation" = list(name="SVD", param=list(k = 50))
)
```

```{r,echo=TRUE,results='hide'}
results <- evaluate(scheme, algorithms, type = "topNList", n=c(seq(10, 500, by = 50)))
```
## Roc curve 
```{r,echo=TRUE}
 plot(results, annotate=c(1,3), legend="bottomright")

```
